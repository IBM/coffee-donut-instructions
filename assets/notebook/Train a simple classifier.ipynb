{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Image Classification for Coffee or Donuts\n\nIs the given image a coffee photo, or a donut?\nIn this demo notebook we build a simple deep neural network to classify an image as one of the following:\n- coffee\n- mug\n- donut\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Install Prerequisites\n\nWe use Keras/Tensorflow to build the classification model, and visualize the process with matplotlib."}, {"metadata": {}, "cell_type": "code", "source": "# Import required libraries\nfrom botocore.client import Config\nimport ibm_boto3\n!pip install tensorflow==1.15\nimport tensorflow as tf\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Read The Data\n\nHere we build simple wrapper functions to read in the data from our cloud object storage buckets and extract it. First, we need the credentials from cloud object store. \n\nOpen the data side bar (0100). Click on the dropdown for \"coffee-donuts-segregated.zip\" file and insert \"credentials\""}, {"metadata": {}, "cell_type": "code", "source": "# open the data side bar (0100). Click on the dropdown for \"coffee-donuts-segregated.zip\" file \n# and insert \"credentials\"\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "credentials =  # paste the credentials variable from the last cell. This is something like credentials_number", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "A download function from IBM Cloud"}, {"metadata": {}, "cell_type": "code", "source": "def download_file_cos(credentials, local_file_name, key): \n    '''\n    Wrapper function to download a file from cloud object storage using the\n    credential dict provided and loading it into memory\n    '''\n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials['BUCKET'],Key=key,Filename=local_file_name)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('File Downloaded')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# change credentials_1 to the variable that was assigned when insertering credentials\ndownload_file_cos(credentials,'coffee-donuts-segregated.zip','coffee-donuts-segregated.zip')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from io import BytesIO\nimport zipfile\n\n    \nwith zipfile.ZipFile('coffee-donuts-segregated.zip', 'r') as zipObj:\n   # Extract all the contents of zip file in current directory\n   zipObj.extractall()", "execution_count": null, "outputs": []}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#you just downloaded some pictures in the local runtime that we will use the train our model\n!ls -ltrh data", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Build the Model\n\nWe start with a [MobileNetV2](https://arxiv.org/abs/1801.04381) architecture as the backbone [pretrained feature extractor](https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet). We then add a couple of dense layers and a softmax layer to perfom the classification. We freeze the MobileNetV2 backbone with weights trained on ImageNet dataset and only train the dense layers and softmax layer that we have added."}, {"metadata": {}, "cell_type": "code", "source": "base_model=tf.keras.applications.MobileNetV2(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\nx=base_model.output\nx=tf.keras.layers.GlobalAveragePooling2D()(x)\nx=tf.keras.layers.Dense(512,activation='relu')(x) #dense layer 1\nx=tf.keras.layers.Dense(256,activation='relu')(x) #dense layer 2\npreds=tf.keras.layers.Dense(3,activation='softmax')(x) #final layer with softmax activation\n\nmodel=tf.keras.Model(inputs=base_model.input,outputs=preds)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Freeze layers from MobileNetV2 backbone (not to be trained)\nfor layer in base_model.layers:\n    layer.trainable=False", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Prepare the training dataset as a data generator object\ntrain_datagen=tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input) #included in our dependencies\n\ntrain_generator=train_datagen.flow_from_directory('data',\n                                                 target_size=(224,224),\n                                                 color_mode='rgb',\n                                                 batch_size=10,\n                                                 class_mode='categorical',\n                                                 shuffle=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Using Adam, categorical_crossentropy and accuracy as optimization method, loss function and metrics, respectively"}, {"metadata": {}, "cell_type": "code", "source": "# Build the model\nmodel.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Train the model"}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "from tensorflow import set_random_seed\nset_random_seed(2)\nstep_size_train=5\nlog_file = model.fit_generator(generator=train_generator,\n                   steps_per_epoch=step_size_train,\n                   epochs=4)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Figure of Training Loss and Accuracy"}, {"metadata": {}, "cell_type": "code", "source": "# Model accuracy and loss vs epoch\nplt.plot(log_file.history['acc'], '-bo', label=\"train_accuracy\")\nplt.plot(log_file.history['loss'], '-r*', label=\"train_loss\")\nplt.title('Training Loss and Accuracy')\nplt.ylabel('Loss/Accuracy')\nplt.xlabel('Epoch #')\nplt.legend(loc='center right')\nplt.show()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Model Performance\n\nHere we perform inference on some sample data points to determine the performance of the model"}, {"metadata": {}, "cell_type": "code", "source": "# Mapping labels \nlabel_map = (train_generator.class_indices)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "label_map", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Creating a sample inference function\ndef prediction(image_path, model):\n    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n    x = tf.keras.preprocessing.image.img_to_array(img)\n    x = np.expand_dims(x, axis=0)\n    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n    preds = model.predict(x)\n    #print('Predictions', preds)\n    \n    for pred, value in label_map.items():    \n        if value == np.argmax(preds):\n            print('Predicted class is:', pred)\n            print('With a confidence score of: ', np.max(preds))\n    \n    return np.argmax(preds)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#change credentials_1 to the variable that was assigned when insertering credentials\ndownload_file_cos(credentials,'Coffee.jpg','Coffee.jpg')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Opening first image\nimage = Image.open(\"Coffee.jpg\")\nimage", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#performing inference on above image\nprediction('Coffee.jpg', model)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Opening second image\n#change credentials_1 to the variable that was assigned when insertering credentials\ndownload_file_cos(credentials,'Mug.jpg','Mug.jpg')\nimage = Image.open(\"Mug.jpg\")\nimage", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "prediction('Mug.jpg', model)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Opening third image\n#change credentials_1 to the variable that was assigned when insertering credentials\ndownload_file_cos(credentials,'Donut.jpg','Donut.jpg')\nimage = Image.open(\"Donut.jpg\")\nimage", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "prediction('Donut.jpg', model)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Thank you for attending!"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}